# -*- coding: utf-8 -*-
"""PROJECT DEMO -  ClassificationOfEpilepsyDataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vcqhfbW67Lwmuxbzn8YKnHHYwlQhuhAq?usp=sharing

# **Import of all libraries needed.**
"""

# Citation: https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.html#module-matplotlib.pyplot
import matplotlib.pyplot as plt

# Citation: https://numpy.org/doc/
import numpy as np

# Citation: https://docs.scipy.org/doc/scipy/reference/io.html
import scipy.io

# Citation: https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html
from sklearn.cluster import KMeans

# Citation: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html
from sklearn.svm import SVC

# Citation: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html
from sklearn.metrics import accuracy_score

# Citation: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html
from sklearn.neighbors import KNeighborsClassifier

# Citation: https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AffinityPropagation.html
from sklearn.cluster import AffinityPropagation

# Citation: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.euclidean_distances.html#sklearn.metrics.pairwise.euclidean_distances
from sklearn.metrics import euclidean_distances

# Citation: https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.pdist.html
from scipy.spatial.distance import pdist

# Citation: https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.squareform.html
from scipy.spatial.distance import squareform

# Citation: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix
from sklearn.metrics import confusion_matrix

# Citation: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn-metrics-f1-score
from sklearn.metrics import f1_score

# Citation: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.normalize.html#sklearn-preprocessing-normalize
from sklearn.preprocessing import normalize

"""# **Loading the dataset**

---


The preprocessed dataset is loaded, ready to be further processed via the pipeline.
"""

# Citation: https://www.kaggle.com/crawford/reading-mat-files-into-python and
#           https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.loadmat.html
epilepsy_dataset = scipy.io.loadmat("/content/drive/My Drive/Epilepsy_data_denoised.mat")

# normal_den_values and patient_den_values are both arrays of 2D arrays. 
normal_den_values  = epilepsy_dataset.get("NORMAL_den")  # 200 x 90 x  80
patient_den_values = epilepsy_dataset.get("PATIENT_den") # 200 x 90 x 100

"""# **Feature Extraction**

---
"""

def functional_similarity(runs, k, unlabelled_data):
  
  """
  This function returns a 'community matrix' of type ndarray and shape (90, 90)
  that represents the probability (ranging from 0 to 1) that BRi and BRj belong
  to the same functional community (Rajpoot et al., 2015).

  A community matrix is generated via the average of 'runs' amount of
  'connectivity matrices'. A connectivity matrix represents the functional
  connectivity of pairs of brain regions. Each brain region (BR) is compared to
  all other brain regions. If BRi and BRj belong to the same cluster, then they
  are deemed as functionally similiar and, therefore, is represented via a '1'
  in the connectivity matrix. Else, they are deemed as a '0'.

  Precondition: unlabelled_data MUST be of shape (90, 200)

  Connectivity matrix: This is a binary matrix of shape (90, 90) whereby '1'
                       represents that BRi and BRj are functionally similar and
                       '0' if not.

                       For example, if we had three brain regions with two
                       clusters x and y, we may end up with labels in the form
                       'labels = [x, y, x]'. Each element indicates a brain
                       region (BR), so index 0 indicates the first brain region,
                       index 1 the second brain region, and index 2 the third
                       brain region.
                       
                       The first brain region (BR0) is assigned to the 'x'
                       cluster; BR1 is assigned to the 'y' cluster; BR3 is 
                       assigned to the 'x' cluster.

                       We use a nested for loop to iterate through the 1D
                       ndarray and check whether pairs of brain regions belong
                       to the same cluster. For example, BR0 and BR0 clearly
                       both belong to the same cluster, so the connectivity
                       matrix places a '1' in the [0, 0] region.
                       
                       Next, BR0 is compared to BR1. As these do not belong to
                       the same cluster, a '0' is assigned to the connectivity
                       martix at position [0, 1].

                       This pattern contines until the 90x90 connectivity
                       matrices is fully populated.

                               j             labels = [x, y, x]
                               |                 
                               V             for i in range (0, len(labels)):
                        i -> [[1 0 1]           for j in range(0, len(labels)):
                              [0 1 0]               
                              [1 0 1]] 

  Paramaters
  ----------
  runs (int):
      The amount of times the kmeans algorithm will be executed. This is
      not to be confused with iterations. For example, one run will
      contain numerous iterations. 
  
  k (int):
      The amount of clusters to be formed.

  unlabelled_data (ndarray) of shape (90, 200):
      The dataset containing information for a single participant's 90 brain
      regions across 200 time series. For example:

      [[BR01 BR01 BR01 ... BR01]  # length = 200
       [BR02 BR02 BR02 ... BR02]  # length = 200
        ...
       [BR90 BR90 BR90 ... BR90]] # length = 200

  Returns
  -------
  community_matrix (ndarray) of shape (90, 90):
      A single community matrix of shape (90, 90) that is the average of all the
      connectivity matrices ('runs' amount in total) generated.
  
  Reference(s)
  --------
      Rajpoot, K., Riaz, A., Majeed, W., & Rajpoot, N. (2015). Functional
      connectivity alterations in epilepsy from resting-state functional MRI.
      PLOS ONE, 10(8), 1–19. https://doi.org/10.1371/journal.pone.0134944
  
  """

  # Stores the connectivity matrix generated per each run. Will therefore
  # contain 'runs' amount of connectivity matrices.
  # Citation: https://stackoverflow.com/questions/19348448/how-to-store-multiple-numpy-2d-matrices-with-different-sizes-into-one-numpy
  all_connectivity_matrices = [] 

  for run in range(0, runs):

    # Citation: The KMeans algorithm is processed via the KMeans class as part
    # of the sklearn.cluster library.
    # (https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)
    kmeans              = KMeans(n_clusters=k, init='random')
    cluster_labels      = kmeans.fit_predict(unlabelled_data)
    labels_length       = len(cluster_labels)
    connectivity_matrix = np.zeros((labels_length, labels_length))

    for i in range(0, labels_length):
      for j in range(0, labels_length):

        if cluster_labels[i] == cluster_labels[j]:
          
          connectivity_matrix[i, j] = 1
        
        else: # If the two regions do not belong to the same cluster
          
          connectivity_matrix[i, j] = 0

    # Store the connectvity matrix.
    all_connectivity_matrices.append(connectivity_matrix)

  # Debug
  assert runs == len(all_connectivity_matrices)

  # Create community matrix:
  # The list of connectivity matrices must be converted to a ndarray first so
  # that we can reshape it from a 3D ndarray into a 2D ndarray. The reshaping
  # of the array lines up the same brain regions from separate connectivity
  # matrices into the same column, so that the mean can be easily calculated.
  array = np.array(all_connectivity_matrices).reshape(len(all_connectivity_matrices), 8100)
  community_matrix = np.mean(array, axis=0).reshape(90, 90)

  # Debug
  assert community_matrix.shape == (90, 90)  

  return community_matrix

def save_cm(community_matrices, k, identifier):
  """
  Converts the list of community matrices for the population into an ndarray
  and saves it as a .npy file

  Parameters
  ----------
  community_matrices (list):
    A 3D list of all community matrices for all the participants of the 
    respective population.
  
  k (int):
    The k value that has been used to cluster all the community matrices.
  
  identifier (String):
    A string that identifies whether the population of community matrices are
    from the healthy or epileptic population. 

  Returns
  -------

  void
  """

  debug = 1

  ndarray_to_be_stored = np.array(community_matrices)
  file_name            = f"{identifier}_k{k}_cm.npy"
  np.save(file_name, ndarray_to_be_stored)

  if debug == 1:
    print(">>>>> community_matrices=\n", community_matrices)
    print(">>>>k= ", k)
    print(">>>> identifier= ", identifier)

    print(">>>> ndarray_to_be_stored=\n", ndarray_to_be_stored)
    print(">>>>> file_name= ", file_name)
  
  else:
    pass

"""# **Feature Extraction: Healthy patients**

---
"""

debug = 1

IDENTIFIER = "healthy"
RUNS       = 500
k          =  35

all_healthy_participants_k35_cm = []

for i in range(0, 80):

  if debug == 1:
    print(">>>>> i=", i)
  
  else:
    pass

  healthy_participant = normal_den_values[:, :, i]
  healthy_participant_transposed = healthy_participant.T
  community_matrix = functional_similarity(RUNS, k, healthy_participant_transposed)
  all_healthy_participants_k35_cm.append(community_matrix)

# Save all the community matrices for each participant as a .npy file.
save_cm(all_healthy_participants_k35_cm, k, IDENTIFIER)

if debug == 1:
  print(">>>>> len(all_healthy_participants_k35_cm)= ", len(all_healthy_participants_k35_cm))
  print(">>>> all_healthy_participants_k35_cm=\n", all_healthy_participants_k35_cm)

else:
  pass

"""# **Feature Extraction: Epileptic patients**

---
"""

debug = 1

IDENTIFIER = "epileptic"
RUNS       = 500
k          =  35

all_epileptic_patients_k35_cm = []

for i in range(0, 100):

  if debug == 1:
    print(">>>>i= ", i)
  
  else:
    pass

  epileptic_patient = patient_den_values[:, :, i]
  epileptic_patient_transposed = epileptic_patient.T
  community_matrix = functional_similarity(RUNS, k, epileptic_patient_transposed)
  all_epileptic_patients_k35_cm.append(community_matrix)

# Save all the community matrices for each participant as a .npy file.
save_cm(all_epileptic_patients_k35_cm, k, IDENTIFIER)

if debug == 1:
  print(">>>>>> len(all_epileptic_patients_k35_cm)", len(all_epileptic_patients_k35_cm))
  print(">>>>>> all_epileptic_patients_k35_cm=\n", all_epileptic_patients_k35_cm)

else:
  pass

"""# **Visualisation: The Averages**

---

Here we take the average community matrices per population and compare them visually.
"""

def mean_community_matrix(population):
  """
  Calculates an average community matrix for the population via all
  participant's community matrices in said population. 

  Computes and returns a community matrix (ndarray) of shape (90, 90) that
  represents the mean probability that pairs of brain regions are
  part of the same functional community for either the healthy of epileptic
  population.

  The population may contain all participants of the population, or it may
  contain only half, as is the case when creating training data.

  Parameters
  ---------

  population (ndarray) of shape (x, 90, 90):
    Contains all community matrices for either the healthy or epileptic
    population, generated via a specific 'k' value.
    
    'x' is either 80 or 100 (representing the entire healthy or epileptic
    population, respectively), or 40 or 50 (representing half of the the healthy
    or epileptic population, respectively). 

  Returns
  -------
  
  Returns the mean community matrix of a population. 

  """
  amount_of_participants = len(population)

  # Debug
  assert (amount_of_participants == 100 or amount_of_participants == 80) or (amount_of_participants == 40 or amount_of_participants == 50)

  # The ndarray containing the community matrices is reshaped from 3D to 2D so
  # that the mean can be efficiently calculated via the numpy.mean() function.
  return np.mean(population.reshape(amount_of_participants, 8100), axis=0).reshape(90, 90)

def visualise_average_pop_cm(healthy_pop, epileptic_pop, k):
  """
  Averages the community matrices for the healthy and epileptic populations via
  the mean_community_matrix(population) function and then visualises them.

  Parameters
  ----------

  healthy_pop (ndarray) of shape (80, 90, 90):
    A 3d numpy.ndarray of all healthy parcipants' community matrices for a
    particular k value. The community matrices will have been formed via a
    k-means cluster analysis. 

  epileptic_pop (ndarray) of shape (100, 90, 90):
    A 3d numpy.ndarray of all epileptic parcipants' community matrices for a
    particular k value. The community matrices will have been formed via a
    k-means cluster analysis.

  k (int):
    The k value used in the k-means implementation to produce the original
    community matrices.

  Returns
  -------

  void

  """

  debug = 0

  # The ndarrays containing the community matrices are reshaped from 3D to 2D so
  # that the average can be efficiently calculated via the numpy.mean() function.
  average_cm_healthy   = mean_community_matrix(healthy_pop)
  average_cm_epileptic = mean_community_matrix(epileptic_pop)

  if debug == 1:
    print(">>>>> average_cm_healthy.shape= ", average_cm_healthy.shape)
    print(">>>>> average_cm_epileptic.shape= ", average_cm_epileptic.shape)
    
    print(f">>>>> average_cm_healthy_k{k}=\n", average_cm_healthy)
    print(f">>>>> average_cm_epileptic_k{k}=\n", average_cm_epileptic)
  
  else:
    pass


  # Plotting two visuals per output was based on the following citation's code.
  # Citation: https://matplotlib.org/tutorials/introductory/images.html
  fig = plt.figure(figsize=[20, 20])
  ax = fig.add_subplot(1, 2, 1)

  # Citation: https://matplotlib.org/api/_as_gen/matplotlib.pyplot.imshow.html
  plt.imshow(average_cm_healthy)

  # Citation: https://matplotlib.org/api/_as_gen/matplotlib.pyplot.colorbar.html
  plt.colorbar(orientation='horizontal')
  ax.set_title(f"Average cm: healthy k = {k}")
  
  ax2 = fig.add_subplot(1, 2, 2)

  # Citation: https://matplotlib.org/api/_as_gen/matplotlib.pyplot.imshow.html
  plt.imshow(average_cm_epileptic)

  # Citation: https://matplotlib.org/api/_as_gen/matplotlib.pyplot.colorbar.html
  plt.colorbar(orientation='horizontal')
  ax2.set_title(f"Average cm: epileptic k = {k}")

  plt.show()
  plt.close(fig)

# Previously generated community matrices for all participants (both healthy and
# epileptic) are loaded into the program.
healthy_pop_cm_k35   = np.load("/content/drive/My Drive/EXTRA_k_means_connectivity_matrices_results/healthy_k35_cm.npy")
epileptic_pop_cm_k35 = np.load("/content/drive/My Drive/EXTRA_k_means_connectivity_matrices_results/epileptic_k35_cm.npy")

# Here we create average community matrices for the two populations and
# visualise them for comparison. 
visualise_average_pop_cm(healthy_pop_cm_k35, epileptic_pop_cm_k35, 35)

"""# **Feature Selection and Classification**


---
Here we conduct a feature selection and the subsequent classification process.
"""

# Previously generated community matrices for all participants (both healthy and
# epileptic) are loaded into the program.
healthy_pop_cm_k35   = np.load("/content/drive/My Drive/EXTRA_k_means_connectivity_matrices_results/healthy_k35_cm.npy")
epileptic_pop_cm_k35 = np.load("/content/drive/My Drive/EXTRA_k_means_connectivity_matrices_results/epileptic_k35_cm.npy")

def construct_difference_matrix(healthy_pop, epileptic_pop):
  """
  Constructs and returns a 'difference matrix' which is a 2D ndarray of shape
  (90, 90) representing the differene statistic. The difference statistic
  represents the discriminatory power between the ith and jth brain regions
  (Rajpoot et al., 2015)

  Precondition: healthy_pop and epileptic_pop must have been calculated with the
                same k value. 

  Parameters
  ----------

  healthy_pop (ndarray) of shape (x, 90, 90):
    A 3d numpy.ndarray of all healthy parcipants' community matrices for a
    particular k value. The community matrices will have been formed via a
    k-means cluster analysis. 'x' may represent 80 in the case of forming a 
    difference matrix for all of the healthy participants, or 40 in the case
    of forming a difference matrix for half of the popultion that has been
    randomly selected as training data.

  epileptic_pop (ndarray) of shape (x, 90, 90):
    A 3d numpy.ndarray of all epileptic parcipants' community matrices for a
    particular k value. The community matrices will have been formed via a
    k-means cluster analysis. 'x' may represent 100 in the case of forming a 
    difference matrix for all of the healthy participants, or 50 in the case
    of forming a difference matrix for half of the popultion that has been
    randomly selected as training data.

  Returns
  -------

  Returns a 'difference matrix' D(i, j) that is the result of the mean
  community matrix of the epilepetic population subtracted from the mean
  community matrix of the healthy population.

  Reference(s)
  -----------
  
  Rajpoot, K., Riaz, A., Majeed, W., & Rajpoot, N. (2015). Functional
  connectivity alterations in epilepsy from resting-state functional MRI.
  PLOS ONE, 10(8), 1–19. https://doi.org/10.1371/journal.pone.0134944
  ‌
  """
  
  debug = 0

  # The ndarrays containing the community matrices are reshaped from 3D to 2D so
  # that the average can be efficiently calculated via the numpy.mean() function.
  mean_cm_healthy   = mean_community_matrix(healthy_pop)
  mean_cm_epileptic = mean_community_matrix(epileptic_pop)

  # Difference matrix is calculated via subtracting the mean community matrix
  # of the epileptic population from the mean community matrix of the healthy
  # population (Rajpoot et al., 2015).
  # Citation: https://stackoverflow.com/questions/38179248/absolute-difference-of-two-numpy-arrays
  difference_matrix = np.absolute((np.subtract(mean_cm_healthy, mean_cm_epileptic)))

  if debug == 1:
    print(">>>>> mean_cm_healthy.shape= ", mean_cm_healthy.shape)
    print(">>>>> mean_cm_epileptic.shape= ", mean_cm_epileptic.shape)
    
    print(">>>>> mean_cm_healthy=\n", mean_cm_healthy)
    print(">>>>> mean_cm_epileptic=\n", mean_cm_epileptic)

    print(">>>> difference_matrix.shape= ", difference_matrix.shape)
    print(">>>> difference_matrix=\n", difference_matrix)
  
  else:
    pass

  # Debug
  assert difference_matrix.shape == (90, 90)

  return difference_matrix

def randomly_split_data(population):
  """
  Randomly splits the community matrices of a popultion formed via a particular
  'k' value into two different sets: training data and testing data.

  Parameters:
  ----------

  population (ndarray) of shape (x, 90, 90):
    Contains all community matrices for either the healthy or epileptic
    population, generated via a specific 'k' value. 'x' is either 80 or 100,
    representing either the healthy or epileptic population, respectively.
  
  Returns
  -------
  A list with two elements. The first containing the community matrices for
  those subjects randomly selected to be the training data. The second
  containing the community matrices for those subjects that were not randomly
  selected to be part of the training data, and so act as the test data. 

  """
  
  debug = 0

  training_data                   = []
  test_data                       = []
  training_and_test_data_combined = []

  # 1) Half of the participant's community matrices from the population are
  #    randomly chosen to be the training data. The other half will be the test
  #    data. The random selection process is repeated if duplicate indices are
  #    extracted. 

  duplicates = True

  while (duplicates): 
    
    # Citation: MSeifert, https://stackoverflow.com/questions/43506766/randomly-select-from-numpy-array
    n = int(population.shape[0] / 2)
    training_indices = np.random.choice(population.shape[0], n, replace=False)

    # Test for duplicates: if all the indices randomly selected are unique, then
    # we do not need to randomly select again. 
    if (len(np.unique(training_indices)) == n):
      duplicates = False
    
    # Else, there are duplicates and the random selction process is re-run. 
    else:
      pass

  # Debug 
  assert len(training_indices) == 40 or len(training_indices) == 50

  # 2) As we now have the indices of those participant's who belong to the
  #    training_data set and those who do not, we iteratre through all
  #    participant's and sort them as such. 
  for index in range(0, len(population)): # len(popoulation) == 80 or 100
    
    # If the index is in the training_indices array, then we put that
    # participant's community matrix inside the training_data list. 
    if index in training_indices:
      training_data.append(population[index])

    # Else, the participant's community matrix has been chosen to be included
    # in the test data. 
    else:
      test_data.append(population[index]) 

  # Debug
  assert (len(training_data) == len(population) / 2) and (len(test_data) == len(population) / 2)

  # 3) The training and test data are packaged as ndrrays into a list. This list
  #    is then returned and can be further unpackaged into training data and
  #    test data.
  training_and_test_data_combined.append(np.array(training_data))
  training_and_test_data_combined.append(np.array(test_data))
 
  if debug == 1:
    print(">>>>> int(population.shape[0] / 2)= ", int(population.shape[0] / 2))

    print(">>>>> population.shape= ", population.shape)
    print(">>>>> population=\n", population)

    print(">>>> len(training_indices)= ", len(training_indices))
    print(">>>> training_indices= ", training_indices)

    print(">>>> len(training_data)= ", len(training_data))
    print(">>>> training_data=\n", training_data)

    print(">>>> len(training_and_test_data_combined)= ", len(training_and_test_data_combined))
    print(">>>> training_and_test_data_combined=\n", training_and_test_data_combined)
  
  else:
    pass

  return training_and_test_data_combined

def extract_h_positions(difference_matrix, h):
  """
  Extracts and returns a list of the indices of the maximum 'h' values from the
  difference matrix provided.
  

  Precondition(s)
  --------------

  The difference matrix will have been constructed via participants from both
  populations via a random selection process.
  
  h must be either 300, 350, 400, 450, 500, 550, 600 

  Parameters
  ----------

  difference_matrix (ndarray) of shape (90, 90):
    A difference matrix based on the randomly selected training subjects of the
    healthy and epileptic populations formed via a particular 'k' value.
    This is used to identify the maximum 'h' values's indices which will be
    used to extract individual subject's data as training data for a futuure
    classifier.

  h (int):
    The number of indices to extract that represent the maximum values in the
    difference matrix.

  Returns
  -------
  A list of tuples that represent the indices of the h maximum values in the
  difference matrix.
  
  """
  # Create a copy so the original difference matrix is not altered. 
  difference_matrix_copy    = np.copy(difference_matrix)
  all_indices_of_max_values = []

  for i in range(0, h):
  
    # Returns the index of the current maximum value in the difference matrix in
    # tuple form.
    # Citation: https://numpy.org/doc/stable/reference/generated/numpy.argmax.html
    index = np.unravel_index(np.argmax(difference_matrix_copy, axis=None), difference_matrix_copy.shape)

    # Add index to the list of all indices that represent h amount of maximum
    # values.
    all_indices_of_max_values.append(index)

    # Set the current max value in the difference matrix to a negative via the
    # indices so that it is not found again.
    difference_matrix_copy[index] = -1
  
  return all_indices_of_max_values

def extract_biomarkers(training_data, indices_of_max_values):
  """
  Extracts and returns a vector of biomarkers that represent the input
  attributes of training data for classification at a later stage. The vector
  contains the biomarkers of ALL subjects from the training data. 

  Parameters
  ----------

  training_data (ndarray) of shape (x, 90, 90):
    An ndarray containing community matrices of those participants who were
    randomly selected to be used as training data. 
       
    x is either 40 or 50, representing the healthy or epileptic training
    participants, respectively.


  indices_of_max_values (list of tuples):
    A list of tuples that contain the indices that are used to extract the
    biomarkers from each subject. The list will be of length h.
  
  Returns
  -------
  Returns a vector of biomarkers that represent input attributes. The vector is
  in the form of a ndarray with shape ()

  """

  debug = 0

  if debug == 1:
    print(">>>>>> training_data.shape= ", training_data.shape)
    print(">>>>>> training_data=\n", training_data)

    print(">>>>> indices_of_max_values= ", indices_of_max_values)

  else:
      pass

  # A vector of biomarkers that represent the input attributes of training data
  # for classification at a later stage. It contains the biomarkers of ALL
  # subjects from the training data. 
  features_selected = []

  for subjects_cm in training_data:

    if debug == 1:
      print(">>>>> subjects_cm.shape= ", subjects_cm.shape)
      print(">>>>> subjects_cm=\n", subjects_cm)
    
    else:
      pass

    # Use the indices to get the values from a single subject's community matrix
    for index in indices_of_max_values:
    
      # 3) Append the community matrix value into a list. 
      features_selected.append(subjects_cm[index])

  # The biomarkers are reshaped and returned as an ndarray of shape (x, h),
  # where x is either 40 or 50 and h is the amount of maximum valued features
  # selected:
  # 
  # [[Bio1 Bio2 Bio3 ... Bioh],  <-- Participant 1
  #  [Bio1 Bio2 Bio3 ... Bioh],  <-- Participant 2
  #  ...
  #  [Bio1 Bio2 Bio3 ... Bioh]]  <-- Participant 40 or 50
  return np.array(features_selected).reshape(len(training_data), len(indices_of_max_values))

def create_class_labels():
  """
  Returns an ndarray of shape (90, ) containing the y_true labels for the
  classificaton. Class: 0 = healthy, and 1 = epileptic.

  Returns
  -------
  Returns an ndarray of shape (90, ) containing the y_true labels for the
  classificaton.

  """

  y = []

  for i in range(0, 90):
    
    if i < 40:
      y.append(0)
    
    else: # Else, if i >= 40
      y.append(1)

  return np.array(y)

def classification_evaluation(y_true, predicted_labels):
  """
  Evalutes the results of the machine learning model via four different
  measures: accuracy, sensitivity, specificity, precision, and f1 score.

  The results are returned in an ndarray: [A, sens, spec, pres, f1score]. 

  Parameters
  ----------
  y_true (ndarray):
    An ndarray of shape (90, ) containing the true labels (classes). 
  
  predicted_labels (ndarray):
    An ndarray of shape (90, ) containing the labels (classes) that were
    predicted via the trained machine learning model. 

  Returns
  -------
  An ndarray of the evaluation results. 

  """

  # classification_report is a list
  # object of numeric values [A, sens, spec, pres].
  # A = Classification accuracy; Sens = Sensitivity; Spec = Specificity; 
  # Prs = Precision value.
  classification_report_list = []

  # The machine learning model is evaluated. Firstly, the true negative (tn),
  # false positive (fp), false negative (fn), and true positive (tp) values
  # are extracted.
  # Citation: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix
  tn, fp, fn, tp = confusion_matrix(y_true, predicted_labels).ravel()
  
  # Citation: The accuracy_score function is implemented via the
  # sklearn.metrics library.
  # (https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)
  A               = accuracy_score(y_true, predicted_labels) * 100
  
  # Citation: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html
  f1score         = f1_score(y_true, predicted_labels) * 100
  sensitivity     = (tp / (tp + fn))                   * 100
  specificity     = (tn / (tn + fp))                   * 100
  precision_value = (tp / (tp + fp))                   * 100

  classification_report_list.append(A)
  classification_report_list.append(sensitivity)
  classification_report_list.append(specificity)
  classification_report_list.append(precision_value)
  classification_report_list.append(f1score)

  return np.array(classification_report_list)

def classification(classifier, X, test_input_features, k):
  """
  Trains a machine learning model and tests said model with training and test
  data, repsectively. The accuracy percentage of the model is then calculated
  via the sklearn.metrics.accuracy_score class and returned. 

  Parameters
  ----------

  classifier (String):
    The type of classifier to be used, such as SVM or K-NN.
  
  X (ndarray) of shape (90, h):
    The combined training data of both populations that contains h selected
    features. This is the training data that is used to train the
    particular machine learning model. 
  
  test_input_features ():
    The combined test data of both populations that contains h selected
    features. This is the test data that is used to test the particular machine
    learning model.
  
  k (int):
    The k value to be used for determine the k in K-Nearest-Neighbour. 

  Returns
  -------
  Returns the accuracy score of a machine learning classification model. 
  
  """

  # A binary ndarray representing the labels for the training process of
  # classificaion: 0 = healthy and 1 = epileptic.
  y = create_class_labels()

  if classifier == "svm":

    # We first build the machine learning model.
    # Citation: The Support Vector Machines machine leaning process is
    # implemented via the sklearn.svm library and specificlly the SVC class. 
    # (https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html). 
    support_vector_machine = SVC()
    ml_model               = support_vector_machine.fit(X, y)

    # Predictions are made on the test data.
    predicted_labels = support_vector_machine.predict(test_input_features)

    # Returns an evaluation of the machine learning model via a list of several
    # measures. 
    return classification_evaluation(y, predicted_labels)
  
  elif classifier == "knn":
    
    # The machine learning model is instantiated and built. K neighbours matches
    # k clusters used to cluster the particular communinty matrices.
    # Citation: The K-NN machine learning model is implemented via the
    # sklearn.neighbors library and specifically via the KNeighborsClassifier
    # class. (https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)
    knn      = KNeighborsClassifier(n_neighbors=k)
    ml_model = knn.fit(X, y)

    # Predictions are made on the test data.
    predicted_labels = knn.predict(test_input_features)

    # Returns an evulation of the machine learning model via a list of several
    # measures.
    return classification_evaluation(y, predicted_labels)

  else:
    raise Exception(f"Classifier ({classifier}) not recognised.")

def classification_process(healthy_pop_cm, epileptic_pop_cm, iterations, h, classifier, k):
  """
  Performs the entire feature selection and classification process and returns
  the average classification rating for h features selected and the type
  of classifier (SVM or K-NN).

  Parameters
  ----------
  healthy_pop_cm (ndarray) of shape (80, 90, 90):
    Represents all community matrices of the healthy population. 
  
  epileptic_pop_cm (ndarray) of shape (100, 90, 90):
    Represents all community matrices of the epileptic population. 

  iterations (int):
    The amount of times the feature selection and classification stages are
    run. There will be 'iterations' amount of classification accuracy ratings
    generated that will be used to generate an overall mean accuracy rating. 
  
  h (int):
    The number of indices to extract that represent the position of the maximum
    values in the difference matrix.
  
  classifier (String):
    A string representing which classification machine learning to be used
    (either Support Vector Machines or K Nearest Neighbour).
  
  k (int):
    The value used for the K-NN algorithm.

  Returns
  -------
  Returns the mean classification rating for h features selected and the type
  of classifier (SVM or K-NN).

  """

  all_accuracy_results = []

  for i in range(0, iterations):

    # The two populations' community matrices are randomly split 50-50. 
    healthy_training_and_test_data   = randomly_split_data(healthy_pop_cm)
    epileptic_training_and_test_data = randomly_split_data(epileptic_pop_cm)

    # Healthy training and test data.
    healthy_training_data = healthy_training_and_test_data[0]
    healthy_testing_data  = healthy_training_and_test_data[1]

    # Epileptic training and test data.
    epileptic_training_data = epileptic_training_and_test_data[0]
    epileptic_testing_data  = epileptic_training_and_test_data[1]

    # Form a difference matrix from the two sets of training data.
    difference_matrix_training_data = construct_difference_matrix(healthy_training_data, epileptic_training_data)

    # A list of tuples indicating the indices of the maximum values in the
    # difference matrix. The difference matrix was formed via the absolute mean
    # difference of the healthy and epileptic participants randomly seleted to be
    # part of the trainiing data. 
    indices_of_max_values = extract_h_positions(difference_matrix_training_data, h)

    # Feature selection is performed on the training_data: The biomarkers will
    # be used as the input features for the training data. 
    healthy_training_biomarkers   = extract_biomarkers(healthy_training_data, indices_of_max_values)
    epileptic_training_biomarkers = extract_biomarkers(epileptic_training_data, indices_of_max_values)

    # Feature selection is performed on the test data.
    healthy_test_biomarkers   = extract_biomarkers(healthy_testing_data, indices_of_max_values)
    epileptic_test_biomarkers = extract_biomarkers(epileptic_testing_data, indices_of_max_values)

    # The biomarkers/features from the different populations that were extracted
    # as training data are amalgamated and used to train the Support Vector
    # Machine classifer.
    # Citation: https://stackoverflow.com/questions/9775297/append-a-numpy-array-to-a-numpy-array
    X = np.concatenate((healthy_training_biomarkers, epileptic_training_biomarkers), axis=0)

    # The test features are combined into an ndarray of shape (90, h), ready for
    # prediction. 
    # Citation: https://stackoverflow.com/questions/9775297/append-a-numpy-array-to-a-numpy-array
    test_input_features = np.concatenate((healthy_test_biomarkers, epileptic_test_biomarkers), axis=0)

    classification_report = classification(classifier, X, test_input_features, k)
    all_accuracy_results.append(classification_report)  
  
  # Return the average of 'iterations' amount of accuracy, sensitivity,
  # specificity, precision, and f1 score.
  return np.round_(np.mean(np.array(all_accuracy_results), axis=0), 2)

"""# **Classification: SVM**

---

A series of classification experiements with SVM.
"""

# k = 35 experiment
k          =  35
ITERATIONS = 100
CLASSIFIER = "svm"

k_35_h_300_classification_accuracy_result = classification_process(healthy_pop_cm_k35, epileptic_pop_cm_k35, ITERATIONS, 300, CLASSIFIER, k)
k_35_h_350_classification_accuracy_result = classification_process(healthy_pop_cm_k35, epileptic_pop_cm_k35, ITERATIONS, 350, CLASSIFIER, k)
k_35_h_400_classification_accuracy_result = classification_process(healthy_pop_cm_k35, epileptic_pop_cm_k35, ITERATIONS, 400, CLASSIFIER, k)
k_35_h_450_classification_accuracy_result = classification_process(healthy_pop_cm_k35, epileptic_pop_cm_k35, ITERATIONS, 450, CLASSIFIER, k)
k_35_h_500_classification_accuracy_result = classification_process(healthy_pop_cm_k35, epileptic_pop_cm_k35, ITERATIONS, 500, CLASSIFIER, k)
k_35_h_550_classification_accuracy_result = classification_process(healthy_pop_cm_k35, epileptic_pop_cm_k35, ITERATIONS, 550, CLASSIFIER, k)
k_35_h_600_classification_accuracy_result = classification_process(healthy_pop_cm_k35, epileptic_pop_cm_k35, ITERATIONS, 600, CLASSIFIER, k)

print("K value, h value, Average classification result, sensitivity, specificity, precision, f1_score:")

# Printed as a .csv format
for i in range(300, 650, 50):
  print(f"35, {i}", end=', ')
  # Citation: https://www.programiz.com/python-programming/methods/built-in/exec
  program = f"[print(item, end= ', ') for item in k_35_h_{i}_classification_accuracy_result]"
  exec(program)
  print("\n")

"""# **Affinity Propagation**


---
"""

def calculate_preference_values(S, N):
  """
  Returns an ndarray of shape (90, ) that is a programatic representation of
  Rajpoot et al. (2015) preference values formula.

  Parameters
  ----------
  
  S (ndarray) of shape (90, 90):

    Similarity matrix that is used to calculate the preference values.

  N (int):
    N largest values to be picked from S.

  Returns
  -------
  
  Returns preference value ndarray of shape (90, ).

  Reference(s)
  ------------
  
  Rajpoot, K., Riaz, A., Majeed, W., & Rajpoot, N. (2015). Functional
  connectivity alterations in epilepsy from resting-state functional MRI.
  PLOS ONE, 10(8), 1–19. https://doi.org/10.1371/journal.pone.0134944

  """
  
  # Create a copy so the original is not altered. 
  S_copy    = np.copy(S)
  preference_value_array = []

  # For each row in the similrity matrix, we obtain the maximum 'N' values and
  # calculuate the mean. There will be a preference array of shape (90, ) where
  # each value represents the mean value for the particular row. 
  for each_row in range(0, 90):
    
    current_row = S_copy[each_row]
  
    # Here we return the indices of the maximum 'N' values for the vector row.
    # Citation: https://www.w3resource.com/python-exercises/numpy/python-numpy-random-exercise-16.php
    indices_of_max_n_values = np.argsort(current_row)[-N:]

    # Next, we use the indices to return the maximum 'N' values from the vector
    # row. 
    # Citation: https://www.w3resource.com/python-exercises/numpy/python-numpy-random-exercise-16.php
    max_n_values_for_current_row = current_row[indices_of_max_n_values]

    # Take the mean of all the values for the particular vector row S(i, :)
    mean_of_current_row = np.mean(max_n_values_for_current_row)

    # Add it to preference value list.
    preference_value_array.append(mean_of_current_row)

  # Convert the preference value list to an array and return it.
  assert len(preference_value_array) == 90
  return np.array(preference_value_array)

def ap_functional_similarity(unlabelled_data):
  
  """
  This function returns a 'community matrix' of type ndarray and shape (90, 90)
  that represents the probability (ranging from 0 to 1) that BRi and BRj belong
  to the same functional community (Rajpoot et al., 2015).

  The function utilises an Affinity Propogation algorithm implemented via the
  sklearn.cluster.AffinityPropagation class (see also Frey & Dueck, 2007).

  A community matrix is generated via the average of 'runs' amount of
  'connectivity matrices'. A connectivity matrix represents the functional
  connectivity of pairs of brain regions. Each brain region (BR) is compared to
  all other brain regions. If BRi and BRj belong to the same cluster, then they
  are deemed as functionally similiar and, therefore, is represented via a '1'
  in the connectivity matrix. Else, they are deemed as a '0'.

  Precondition: unlabelled_data MUST be of shape (90, 200)

  Connectivity matrix: This is a binary matrix of shape (90, 90) whereby '1'
                       represents that BRi and BRj are functionally similar and
                       '0' if not.

                       For example, if we had three brain regions with two
                       clusters x and y, we may end up with labels in the form
                       'labels = [x, y, x]'. Each element indicates a brain
                       region (BR), so index 0 indicates the first brain region,
                       index 1 the second brain region, and index 2 the third
                       brain region.
                       
                       The first brain region (BR0) is assigned to the 'x'
                       cluster; BR1 is assigned to the 'y' cluster; BR3 is 
                       assigned to the 'x' cluster.

                       We use a nested for loop to iterate through the 1D
                       ndarray and check whether pairs of brain regions belong
                       to the same cluster. For example, BR0 and BR0 clearly
                       both belong to the same cluster, so the connectivity
                       matrix places a '1' in the [0, 0] region.
                       
                       Next, BR0 is compared to BR1. As these do not belong to
                       the same cluster, a '0' is assigned to the connectivity
                       martix at position [0, 1].

                       This pattern contines until the 90x90 connectivity
                       matrices is fully populated.

                               j             labels = [x, y, x]
                               |                 
                               V             for i in range (0, len(labels)):
                        i -> [[1 0 1]           for j in range(0, len(labels)):
                              [0 1 0]               
                              [1 0 1]] 

  Paramaters
  ----------

  unlabelled_data (ndarray) of shape (90, 200):
      The dataset containing information for a single participant's 90 brain
      regions across 200 time series. For example:

      [[BR01 BR01 BR01 ... BR01]  # length = 200
       [BR02 BR02 BR02 ... BR02]  # length = 200
        ...
       [BR90 BR90 BR90 ... BR90]] # length = 200

  Returns
  -------
  community_matrix (ndarray) of shape (90, 90):
      A single community matrix of shape (90, 90) that is the average of all the
      connectivity matrices ('runs' amount in total) generated.
  
  Reference(s)
  --------

  Frey, B. J., & Dueck, D. (2007). Clustering by passing messages between
  data points. Science, 315(5814), 972–976.
  https://doi.org/10.1126/science.1136800‌
    
  Rajpoot, K., Riaz, A., Majeed, W., & Rajpoot, N. (2015). Functional
  connectivity alterations in epilepsy from resting-state functional MRI.
  PLOS ONE, 10(8), 1–19. https://doi.org/10.1371/journal.pone.0134944
  
  """

  # Stores the connectivity matrix generated per each run. Will therefore
  # contain 'N' amount of connectivity matrices.
  # Citation: https://stackoverflow.com/questions/19348448/how-to-store-multiple-numpy-2d-matrices-with-different-sizes-into-one-numpy
  all_connectivity_matrices = []

  # Here we calculate the similarity matrix via the participant's preprocessed
  # rsfMRI data. 
  # Citations: https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.pdist.html
  #           & Rajpoot et al. (2015). 
  S = pdist(unlabelled_data, 'cosine')

  # Debug
  print(">>>> S.shape before squareform= ", S.shape)
  print(">>>> S before squareform=\n", S)

  # The 4005 sparse connections are converted back into a ndarray of (90,90)
  # Citations: https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.squareform.html#scipy.spatial.distance.squareform
  #           & Rajpoot et al. (2015). 
  S = squareform(S)

  # Similarity matrix is normalised.
  # Citation: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.normalize.html#sklearn-preprocessing-normalize
  S = normalize(S)

  # Debug
  print(">>>>> S.shape after squareform= ", S.shape)
  print(">>>> S after squareform=\n", S)

  # We use a particular N value to calculate different preference values
  # which should alter the clusters/exemplars and thus create different
  # connectivty matrices.
  # Citation: The range and step of N is a replicate of the process used via
  #           Rajpoot et al. 2015.
  for N in range(5, 35, 5):

    # Debug
    print(">>>> N= ", N)

    # Here we call a user-defined function to return an ndarray of preference
    # values of shape (90, ).
    preference_val_array = calculate_preference_values(S, N)

    print("++++++++S=\n", S)    

    # Debug
    print(">>>>>>> preference_val_array.shape= ", preference_val_array.shape)
    print(">>>>>>> preference_val_array=\n", preference_val_array)

    # Here, we create the AffinityPropagation instance. 
    # Citation: https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AffinityPropagation.html
    ap = AffinityPropagation(max_iter=5000, preference=preference_val_array, \
                             affinity='precomputed')

    cluster_labels = ap.fit_predict(S)

    # Debug
    print(">>>>>> cluster_labels.shape= ", cluster_labels.shape)
    print(">>>>>> cluster_labels=\n", cluster_labels)

    amount_of_clusters = len(ap.cluster_centers_indices_)

    # Debug
    print(">>>>>> amount of clusters= ", amount_of_clusters)

    labels_length = len(cluster_labels)

    # Debug
    print(">>> labels_length= ", labels_length)

    # Here we construct the connectivity matrix.
    connectivity_matrix  = np.zeros((labels_length, labels_length))

    for i in range(0, labels_length):
      for j in range(0, labels_length):

        # If the two regions belong to the same cluster, then 1 is used as the
        # mark.
        if cluster_labels[i] == cluster_labels[j]:
            
          connectivity_matrix[i, j] = 1
          
        # Else the two regions do not belong to the same cluster and 0 is
        # used as the mark. 
        else:
            
          connectivity_matrix[i, j] = 0

    # Debug
    print(">>>>> connectivity_matrix.shape= ", connectivity_matrix.shape)
    print(">>>>> connectivity_matrix=\n", connectivity_matrix)

    # Here we store the connectvity matrix.
    all_connectivity_matrices.append(connectivity_matrix)

  # Debug
  print(">>>> amount of connectivity matrices= ", len(all_connectivity_matrices))


  # Finally we create and return the community matrix.
  # The list of connectivity matrices must be converted to a ndarray first so
  # that we can reshape it from a 3D ndarray into a 2D ndarray. The reshaping
  # of the array lines up the same brain regions from separate connectivity
  # matrices into the same column, so that the mean can be easily calculated.
  array = np.array(all_connectivity_matrices) \
            .reshape(len(all_connectivity_matrices), 8100)
  
  community_matrix_ap = np.mean(array, axis=0).reshape(90, 90)

  # Debug
  assert community_matrix_ap.shape == (90, 90)  
  print(">>>>>>> community_matrix_ap.shape= ", community_matrix_ap.shape)
  print(">>>>>>> community_matrix_ap=\n", community_matrix_ap)

  return community_matrix_ap

def ap_save_cm(community_matrices, identifier):
  """
  Converts the list of community matrices for the population into an ndarray
  and saves it as a .npy file

  Parameters
  ----------
  community_matrices (list):
    A 3D list of all community matrices for all the participants of the 
    respective population.
  
  identifier (String):
    A string that identifies whether the population of community matrices are
    from the healthy or epileptic population. 

  Returns
  -------

  void
  """

  debug = 0

  ndarray_to_be_stored = np.array(community_matrices)
  file_name            = f"{identifier}_cm.npy"
  np.save(file_name, ndarray_to_be_stored)

  if debug == 1:
    print(">>>>> community_matrices=\n", community_matrices)
    print(">>>> identifier= ", identifier)

    print(">>>> ndarray_to_be_stored=\n", ndarray_to_be_stored)
    print(">>>>> file_name= ", file_name)

  else:
    pass

"""# **Classification: AP: SVM**


---
"""

# Loading from runtime and not the drive.
healthy_cm_ap   = np.load("/content/drive/My Drive/affinity_prop_cms/healthy_ap_cm.npy")
epileptic_cm_ap = np.load("/content/drive/My Drive/affinity_prop_cms/epileptic_ap_cm.npy")

# K is not used for AP.
k          =  -1
ITERATIONS = 100
CLASSIFIER = "svm"

ap_h_300_classification_accuracy_result = classification_process(healthy_cm_ap, epileptic_cm_ap, ITERATIONS, 300, CLASSIFIER, k)
ap_h_350_classification_accuracy_result = classification_process(healthy_cm_ap, epileptic_cm_ap, ITERATIONS, 350, CLASSIFIER, k)
ap_h_400_classification_accuracy_result = classification_process(healthy_cm_ap, epileptic_cm_ap, ITERATIONS, 400, CLASSIFIER, k)
ap_h_450_classification_accuracy_result = classification_process(healthy_cm_ap, epileptic_cm_ap, ITERATIONS, 450, CLASSIFIER, k)
ap_h_500_classification_accuracy_result = classification_process(healthy_cm_ap, epileptic_cm_ap, ITERATIONS, 500, CLASSIFIER, k)
ap_h_550_classification_accuracy_result = classification_process(healthy_cm_ap, epileptic_cm_ap, ITERATIONS, 550, CLASSIFIER, k)
ap_h_600_classification_accuracy_result = classification_process(healthy_cm_ap, epileptic_cm_ap, ITERATIONS, 600, CLASSIFIER, k)


print("h value, Average classification result, sensitivity, specificity, precision, , f1_score:")

# Printed in .csv format
for h in range(300, 650, 50):
  print(h, end=', ')
  # Citation: https://www.programiz.com/python-programming/methods/built-in/exec
  program = f"[print(item, end= ', ') for item in ap_h_{h}_classification_accuracy_result]"
  exec(program)
  print("\n")

"""# **Dynamic functional connectivity (dFc)**


---


Data preprocessing.
"""

def window_kmeans_functional_similarity(runs, k, unlabelled_data):
  
  """
  This function returns a 'community matrix' of type ndarray and shape (90, 90)
  that represents the probability (ranging from 0 to 1) that BRi and BRj belong
  to the same functional community (Rajpoot et al., 2015).

  The community matrix generated is based on a time slice or fixed window, and
  not the full 200 time series. Therefore, this function represents part of
  the dynamic functional connectivity process. 

  A community matrix is generated via the average of 'runs' amount of
  'connectivity matrices'. A connectivity matrix represents the functional
  connectivity of pairs of brain regions. Each brain region (BR) is compared to
  all other brain regions. If BRi and BRj belong to the same cluster, then they
  are deemed as functionally similiar and, therefore, is represented via a '1'
  in the connectivity matrix. Else, they are deemed as a '0'.

  Precondition: unlabelled_data MUST be of shape (90, x). Where x is dependent
  on the window size. 

  Connectivity matrix: This is a binary matrix of shape (90, 90) whereby '1'
                       represents that BRi and BRj are functionally similar and
                       '0' if not.

                       For example, if we had three brain regions with two
                       clusters x and y, we may end up with labels in the form
                       'labels = [x, y, x]'. Each element indicates a brain
                       region (BR), so index 0 indicates the first brain region,
                       index 1 the second brain region, and index 2 the third
                       brain region.
                       
                       The first brain region (BR0) is assigned to the 'x'
                       cluster; BR1 is assigned to the 'y' cluster; BR3 is 
                       assigned to the 'x' cluster.

                       We use a nested for loop to iterate through the 1D
                       ndarray and check whether pairs of brain regions belong
                       to the same cluster. For example, BR0 and BR0 clearly
                       both belong to the same cluster, so the connectivity
                       matrix places a '1' in the [0, 0] region.
                       
                       Next, BR0 is compared to BR1. As these do not belong to
                       the same cluster, a '0' is assigned to the connectivity
                       martix at position [0, 1].

                       This pattern contines until the 90x90 connectivity
                       matrices is fully populated.

                               j             labels = [x, y, x]
                               |                 
                               V             for i in range (0, len(labels)):
                        i -> [[1 0 1]           for j in range(0, len(labels)):
                              [0 1 0]               
                              [1 0 1]] 

  Paramaters
  ----------
  runs (int):
      The amount of times the kmeans algorithm will be executed. This is
      not to be confused with iterations. For example, one run will
      contain numerous iterations. 
  
  k (int):
      The amount of clusters to be formed.

  unlabelled_data (ndarray) of shape (90, x):
      The dataset containing information for a single participant's 90 brain
      regions across x time series. For example, if we used a window size of
      50, then the first window time slice of time slices 1 to 50 would be 
      structured as:

        T1    T2   T3  ...  T50
      [[BR01 BR01 BR01 ... BR01]  # length = 50
       [BR02 BR02 BR02 ... BR02]  # length = 50
        ...
       [BR90 BR90 BR90 ... BR90]] # length = 50

  Returns
  -------
  community_matrix (ndarray) of shape (90, 90):
      A single community matrix of shape (90, 90) that is the average of all the
      connectivity matrices ('runs' amount in total) generated for the
      particular participant.
  
  Reference(s)
  --------
      Rajpoot, K., Riaz, A., Majeed, W., & Rajpoot, N. (2015). Functional
      connectivity alterations in epilepsy from resting-state functional MRI.
      PLOS ONE, 10(8), 1–19. https://doi.org/10.1371/journal.pone.0134944
  
  """

  # Stores the connectivity matrix generated per each run. Will therefore
  # contain 'runs' amount of connectivity matrices.
  # Citation: https://stackoverflow.com/questions/19348448/how-to-store-multiple-numpy-2d-matrices-with-different-sizes-into-one-numpy
  all_connectivity_matrices = [] 

  for run in range(0, runs):

    # Citation: The KMeans algorithm is processed via the KMeans class as part
    # of the sklearn.cluster library.
    # (https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)
    kmeans              = KMeans(n_clusters=k, init='random')
    cluster_labels      = kmeans.fit_predict(unlabelled_data)
    labels_length       = len(cluster_labels)
    connectivity_matrix = np.zeros((labels_length, labels_length))

    for i in range(0, labels_length):
      for j in range(0, labels_length):

        if cluster_labels[i] == cluster_labels[j]:
          
          connectivity_matrix[i, j] = 1
        
        else: # If the two regions do not belong to the same cluster
          
          connectivity_matrix[i, j] = 0

    # Store the connectvity matrix.
    all_connectivity_matrices.append(connectivity_matrix)

  # Debug
  assert runs == len(all_connectivity_matrices)

  # Create community matrix:
  # The list of connectivity matrices must be converted to a ndarray first so
  # that we can reshape it from a 3D ndarray into a 2D ndarray. The reshaping
  # of the array lines up the same brain regions from separate connectivity
  # matrices into the same column, so that the mean can be easily calculated.
  array = np.array(all_connectivity_matrices).reshape(len(all_connectivity_matrices), 8100)
  community_matrix = np.mean(array, axis=0).reshape(90, 90)

  # Debug
  assert community_matrix.shape == (90, 90)  

  return community_matrix

def dfc_save_cm(community_matrices, k, identifier):
  """
  Converts the list of community matrices for the population into an ndarray
  and saves it as a .npy file

  Parameters
  ----------
  community_matrices (list):
    A 3D list of all community matrices for all the participants of the 
    respective population.
  
  k (int):
    The k value that has been used to cluster all the community matrices.
  
  identifier (String):
    A string that identifies whether the population of community matrices are
    from the healthy or epileptic population. 

  Returns
  -------

  void
  """

  debug = 1

  ndarray_to_be_stored = np.array(community_matrices)
  file_name            = f"{identifier}_k{k}_cm.npy"
  np.save(file_name, ndarray_to_be_stored)

  if debug == 1:
    print(">>>>> community_matrices=\n", community_matrices)
    print(">>>>k= ", k)
    print(">>>> identifier= ", identifier)

    print(">>>> ndarray_to_be_stored=\n", ndarray_to_be_stored)
    print(">>>>> file_name= ", file_name)
  
  else:
    pass

"""First we split the data into four different fixed window slices and store it a list."""

debug = 1

# The two lists are used to store the fixed window slices. 
healthy_window_slices   = []
epileptic_window_slices = []

# Time slices for the healthy population in steps of 50. 
first_time_slice_normal  = normal_den_values[   : 50]
second_time_slice_normal = normal_den_values[ 50:100]
third_time_slice_normal  = normal_den_values[100:150]
fourth_time_slice_normal = normal_den_values[150:200]

# Time slices for the healthy population are appended to a list for easy access
# later on.
healthy_window_slices.append(first_time_slice_normal)
healthy_window_slices.append(second_time_slice_normal)
healthy_window_slices.append(third_time_slice_normal)
healthy_window_slices.append(fourth_time_slice_normal)

# Time slices for the epileptic population in steps of 50.
first_time_slice_epilepsy  = patient_den_values[   : 50]
second_time_slice_epilepsy = patient_den_values[ 50:100]
third_time_slice_epilepsy  = patient_den_values[100:150]
fourth_time_slice_epilepsy = patient_den_values[150:200]

# Time slices for the epileptic population are appended to a list for easy
# access later on.
epileptic_window_slices.append(first_time_slice_epilepsy)
epileptic_window_slices.append(second_time_slice_epilepsy)
epileptic_window_slices.append(third_time_slice_epilepsy)
epileptic_window_slices.append(fourth_time_slice_epilepsy)

if debug == 1:
  print(">>>> first_time_slice_normal.shape= ", first_time_slice_normal.shape)
  print(">>>> second= ", second_time_slice_normal.shape)
  print(">>>> third= ", third_time_slice_normal.shape)
  print(">>> fourth= ", fourth_time_slice_normal.shape)

  print(">>>>> ep_first= ", first_time_slice_epilepsy.shape)
  print(">>>>> ep_second= ", second_time_slice_epilepsy.shape)
  print(">>>>> ep_third= ", third_time_slice_epilepsy.shape)
  print(">>>>> ep_fourth= ", fourth_time_slice_epilepsy.shape)

else:
  pass

"""# **dFc: Healthy data processing**



---



Next, we process the healthy data with k-means. We will create separate .npy files for the time_series. We firstly use a k value of 10.
"""

debug = 1

RUNS       = 500
k          =  10

# Used with the identifer to save the community matrices .npy file for a 
# specific window. 1 = first 50 time slices, 2 = next 50 etc.
window_slice_counter = 0

for window_slice in healthy_window_slices:

  # The identifier for the file name is updated to the correct window slice. 
  window_slice_counter = window_slice_counter + 1
  identifier           = f"healthy_window_slice_{window_slice_counter}"

  if debug == 1:
    print(">>>> window_slice_counter= ", window_slice_counter)
  else:
    pass
    
  community_matrices_for_specific_window_slice = []

  for healthy_participant in range(0, 80):

    if debug == 1:
      print(">>>>> healthy_participant_number= ", healthy_participant)
    
    else:
      pass

    healthy_participant_data            = window_slice[:, :, healthy_participant]
    healthy_participant_data_transposed = healthy_participant_data.T
    
    community_matrix_window_slice = window_kmeans_functional_similarity( \
                                  RUNS, k, healthy_participant_data_transposed)
    community_matrices_for_specific_window_slice \
        .append(community_matrix_window_slice)

  # Save all the community matrices for each participant for the specific window
  # as a .npy file.
  dfc_save_cm(community_matrices_for_specific_window_slice, k, identifier)

  # Clear the list so that the next window's community matrices can be stored
  # there.
  community_matrices_for_specific_window_slice.clear()

debug = 1

RUNS       = 500
k          =  15

# Used with the identifer to save the community matrices .npy file for a 
# specific window. 1 = first 50 time slices, 2 = next 50 etc.
window_slice_counter = 0

for window_slice in healthy_window_slices:

  # The identifier for the file name is updated to the correct window slice. 
  window_slice_counter = window_slice_counter + 1
  identifier           = f"healthy_window_slice_{window_slice_counter}"

  if debug == 1:
    print(">>>> window_slice_counter= ", window_slice_counter)
  else:
    pass
    
  community_matrices_for_specific_window_slice = []

  for healthy_participant in range(0, 80):

    if debug == 1:
      print(">>>>> healthy_participant_number= ", healthy_participant)
    
    else:
      pass

    healthy_participant_data            = window_slice[:, :, healthy_participant]
    healthy_participant_data_transposed = healthy_participant_data.T
    
    community_matrix_window_slice = window_kmeans_functional_similarity( \
                                  RUNS, k, healthy_participant_data_transposed)
    community_matrices_for_specific_window_slice \
        .append(community_matrix_window_slice)

  # Save all the community matrices for each participant for the specific window
  # as a .npy file.
  dfc_save_cm(community_matrices_for_specific_window_slice, k, identifier)

  # Clear the list so that the next window's community matrices can be stored
  # there.
  community_matrices_for_specific_window_slice.clear()

debug = 1

RUNS       = 500
k          =  20

# Used with the identifer to save the community matrices .npy file for a 
# specific window. 1 = first 50 time slices, 2 = next 50 etc.
window_slice_counter = 0

for window_slice in healthy_window_slices:

  # The identifier for the file name is updated to the correct window slice. 
  window_slice_counter = window_slice_counter + 1
  identifier           = f"healthy_window_slice_{window_slice_counter}"

  if debug == 1:
    print(">>>> window_slice_counter= ", window_slice_counter)
  else:
    pass
    
  community_matrices_for_specific_window_slice = []

  for healthy_participant in range(0, 80):

    if debug == 1:
      print(">>>>> healthy_participant_number= ", healthy_participant)
    
    else:
      pass

    healthy_participant_data            = window_slice[:, :, healthy_participant]
    healthy_participant_data_transposed = healthy_participant_data.T
    
    community_matrix_window_slice = window_kmeans_functional_similarity( \
                                  RUNS, k, healthy_participant_data_transposed)
    community_matrices_for_specific_window_slice \
        .append(community_matrix_window_slice)

  # Save all the community matrices for each participant for the specific window
  # as a .npy file.
  dfc_save_cm(community_matrices_for_specific_window_slice, k, identifier)

  # Clear the list so that the next window's community matrices can be stored
  # there.
  community_matrices_for_specific_window_slice.clear()

debug = 1

RUNS       = 500
k          =  25

# Used with the identifer to save the community matrices .npy file for a 
# specific window. 1 = first 50 time slices, 2 = next 50 etc.
window_slice_counter = 0

for window_slice in healthy_window_slices:

  # The identifier for the file name is updated to the correct window slice. 
  window_slice_counter = window_slice_counter + 1
  identifier           = f"healthy_window_slice_{window_slice_counter}"

  if debug == 1:
    print(">>>> window_slice_counter= ", window_slice_counter)
  else:
    pass
    
  community_matrices_for_specific_window_slice = []

  for healthy_participant in range(0, 80):

    if debug == 1:
      print(">>>>> healthy_participant_number= ", healthy_participant)
    
    else:
      pass

    healthy_participant_data            = window_slice[:, :, healthy_participant]
    healthy_participant_data_transposed = healthy_participant_data.T
    
    community_matrix_window_slice = window_kmeans_functional_similarity( \
                                  RUNS, k, healthy_participant_data_transposed)
    community_matrices_for_specific_window_slice \
        .append(community_matrix_window_slice)

  # Save all the community matrices for each participant for the specific window
  # as a .npy file.
  dfc_save_cm(community_matrices_for_specific_window_slice, k, identifier)

  # Clear the list so that the next window's community matrices can be stored
  # there.
  community_matrices_for_specific_window_slice.clear()

debug = 1

RUNS       = 500
k          =  30

# Used with the identifer to save the community matrices .npy file for a 
# specific window. 1 = first 50 time slices, 2 = next 50 etc.
window_slice_counter = 0

for window_slice in healthy_window_slices:

  # The identifier for the file name is updated to the correct window slice. 
  window_slice_counter = window_slice_counter + 1
  identifier           = f"healthy_window_slice_{window_slice_counter}"

  if debug == 1:
    print(">>>> window_slice_counter= ", window_slice_counter)
  else:
    pass
    
  community_matrices_for_specific_window_slice = []

  for healthy_participant in range(0, 80):

    if debug == 1:
      print(">>>>> healthy_participant_number= ", healthy_participant)
    
    else:
      pass

    healthy_participant_data            = window_slice[:, :, healthy_participant]
    healthy_participant_data_transposed = healthy_participant_data.T
    
    community_matrix_window_slice = window_kmeans_functional_similarity( \
                                  RUNS, k, healthy_participant_data_transposed)
    community_matrices_for_specific_window_slice \
        .append(community_matrix_window_slice)

  # Save all the community matrices for each participant for the specific window
  # as a .npy file.
  dfc_save_cm(community_matrices_for_specific_window_slice, k, identifier)

  # Clear the list so that the next window's community matrices can be stored
  # there.
  community_matrices_for_specific_window_slice.clear()

debug = 1

RUNS       = 500
k          =  35

# Used with the identifer to save the community matrices .npy file for a 
# specific window. 1 = first 50 time slices, 2 = next 50 etc.
window_slice_counter = 0

for window_slice in healthy_window_slices:

  # The identifier for the file name is updated to the correct window slice. 
  window_slice_counter = window_slice_counter + 1
  identifier           = f"healthy_window_slice_{window_slice_counter}"

  if debug == 1:
    print(">>>> window_slice_counter= ", window_slice_counter)
  else:
    pass
    
  community_matrices_for_specific_window_slice = []

  for healthy_participant in range(0, 80):

    if debug == 1:
      print(">>>>> healthy_participant_number= ", healthy_participant)
    
    else:
      pass

    healthy_participant_data            = window_slice[:, :, healthy_participant]
    healthy_participant_data_transposed = healthy_participant_data.T
    
    community_matrix_window_slice = window_kmeans_functional_similarity( \
                                  RUNS, k, healthy_participant_data_transposed)
    community_matrices_for_specific_window_slice \
        .append(community_matrix_window_slice)

  # Save all the community matrices for each participant for the specific window
  # as a .npy file.
  dfc_save_cm(community_matrices_for_specific_window_slice, k, identifier)

  # Clear the list so that the next window's community matrices can be stored
  # there.
  community_matrices_for_specific_window_slice.clear()

debug = 1

RUNS       = 500
k          =  40

# Used with the identifer to save the community matrices .npy file for a 
# specific window. 1 = first 50 time slices, 2 = next 50 etc.
window_slice_counter = 0

for window_slice in healthy_window_slices:

  # The identifier for the file name is updated to the correct window slice. 
  window_slice_counter = window_slice_counter + 1
  identifier           = f"healthy_window_slice_{window_slice_counter}"

  if debug == 1:
    print(">>>> window_slice_counter= ", window_slice_counter)
  else:
    pass
    
  community_matrices_for_specific_window_slice = []

  for healthy_participant in range(0, 80):

    if debug == 1:
      print(">>>>> healthy_participant_number= ", healthy_participant)
    
    else:
      pass

    healthy_participant_data            = window_slice[:, :, healthy_participant]
    healthy_participant_data_transposed = healthy_participant_data.T
    
    community_matrix_window_slice = window_kmeans_functional_similarity( \
                                  RUNS, k, healthy_participant_data_transposed)
    community_matrices_for_specific_window_slice \
        .append(community_matrix_window_slice)

  # Save all the community matrices for each participant for the specific window
  # as a .npy file.
  dfc_save_cm(community_matrices_for_specific_window_slice, k, identifier)

  # Clear the list so that the next window's community matrices can be stored
  # there.
  community_matrices_for_specific_window_slice.clear()

debug = 1

RUNS       = 500
k          =  45

# Used with the identifer to save the community matrices .npy file for a 
# specific window. 1 = first 50 time slices, 2 = next 50 etc.
window_slice_counter = 0

for window_slice in healthy_window_slices:

  # The identifier for the file name is updated to the correct window slice. 
  window_slice_counter = window_slice_counter + 1
  identifier           = f"healthy_window_slice_{window_slice_counter}"

  if debug == 1:
    print(">>>> window_slice_counter= ", window_slice_counter)
  else:
    pass
    
  community_matrices_for_specific_window_slice = []

  for healthy_participant in range(0, 80):

    if debug == 1:
      print(">>>>> healthy_participant_number= ", healthy_participant)
    
    else:
      pass

    healthy_participant_data            = window_slice[:, :, healthy_participant]
    healthy_participant_data_transposed = healthy_participant_data.T
    
    community_matrix_window_slice = window_kmeans_functional_similarity( \
                                  RUNS, k, healthy_participant_data_transposed)
    community_matrices_for_specific_window_slice \
        .append(community_matrix_window_slice)

  # Save all the community matrices for each participant for the specific window
  # as a .npy file.
  dfc_save_cm(community_matrices_for_specific_window_slice, k, identifier)

  # Clear the list so that the next window's community matrices can be stored
  # there.
  community_matrices_for_specific_window_slice.clear()

debug = 1

RUNS       = 500
k          =  50

# Used with the identifer to save the community matrices .npy file for a 
# specific window. 1 = first 50 time slices, 2 = next 50 etc.
window_slice_counter = 0

for window_slice in healthy_window_slices:

  # The identifier for the file name is updated to the correct window slice. 
  window_slice_counter = window_slice_counter + 1
  identifier           = f"healthy_window_slice_{window_slice_counter}"

  if debug == 1:
    print(">>>> window_slice_counter= ", window_slice_counter)
  else:
    pass
    
  community_matrices_for_specific_window_slice = []

  for healthy_participant in range(0, 80):

    if debug == 1:
      print(">>>>> healthy_participant_number= ", healthy_participant)
    
    else:
      pass

    healthy_participant_data            = window_slice[:, :, healthy_participant]
    healthy_participant_data_transposed = healthy_participant_data.T
    
    community_matrix_window_slice = window_kmeans_functional_similarity( \
                                  RUNS, k, healthy_participant_data_transposed)
    community_matrices_for_specific_window_slice \
        .append(community_matrix_window_slice)

  # Save all the community matrices for each participant for the specific window
  # as a .npy file.
  dfc_save_cm(community_matrices_for_specific_window_slice, k, identifier)

  # Clear the list so that the next window's community matrices can be stored
  # there.
  community_matrices_for_specific_window_slice.clear()

"""# **dfc: Epileptic data processing**


---
"""

debug = 1

RUNS       = 500
k          =  10

# Used with the identifer to save the community matrices .npy file for a 
# specific window. 1 = first 50 time slices, 2 = next 50 etc.
window_slice_counter = 0

for window_slice in epileptic_window_slices:

  # The identifier for the file name is updated to the correct window slice. 
  window_slice_counter = window_slice_counter + 1
  identifier           = f"epileptic_window_slice_{window_slice_counter}"

  if debug == 1:
    print(">>>> window_slice_counter= ", window_slice_counter)
  else:
    pass
    
  community_matrices_for_specific_window_slice = []

  for epileptic_participant in range(0, 100):

    if debug == 1:
      print(">>>>> epileptic_participant_number= ", epileptic_participant)
    
    else:
      pass

    epileptic_participant_data            = window_slice[:, :, epileptic_participant]
    epileptic_participant_data_transposed = epileptic_participant_data.T
    
    community_matrix_window_slice = window_kmeans_functional_similarity( \
                                  RUNS, k, epileptic_participant_data_transposed)
    community_matrices_for_specific_window_slice \
        .append(community_matrix_window_slice)

  # Save all the community matrices for each participant for the specific window
  # as a .npy file.
  dfc_save_cm(community_matrices_for_specific_window_slice, k, identifier)

  # Clear the list so that the next window's community matrices can be stored
  # there.
  community_matrices_for_specific_window_slice.clear()

debug = 1

RUNS       = 500
k          =  15

# Used with the identifer to save the community matrices .npy file for a 
# specific window. 1 = first 50 time slices, 2 = next 50 etc.
window_slice_counter = 0

for window_slice in epileptic_window_slices:

  # The identifier for the file name is updated to the correct window slice. 
  window_slice_counter = window_slice_counter + 1
  identifier           = f"epileptic_window_slice_{window_slice_counter}"

  if debug == 1:
    print(">>>> window_slice_counter= ", window_slice_counter)
  else:
    pass
    
  community_matrices_for_specific_window_slice = []

  for epileptic_participant in range(0, 100):

    if debug == 1:
      print(">>>>> epileptic_participant_number= ", epileptic_participant)
    
    else:
      pass

    epileptic_participant_data            = window_slice[:, :, epileptic_participant]
    epileptic_participant_data_transposed = epileptic_participant_data.T
    
    community_matrix_window_slice = window_kmeans_functional_similarity( \
                                  RUNS, k, epileptic_participant_data_transposed)
    community_matrices_for_specific_window_slice \
        .append(community_matrix_window_slice)

  # Save all the community matrices for each participant for the specific window
  # as a .npy file.
  dfc_save_cm(community_matrices_for_specific_window_slice, k, identifier)

  # Clear the list so that the next window's community matrices can be stored
  # there.
  community_matrices_for_specific_window_slice.clear()

debug = 1

RUNS       = 500
k          =  20

# Used with the identifer to save the community matrices .npy file for a 
# specific window. 1 = first 50 time slices, 2 = next 50 etc.
window_slice_counter = 0

for window_slice in epileptic_window_slices:

  # The identifier for the file name is updated to the correct window slice. 
  window_slice_counter = window_slice_counter + 1
  identifier           = f"epileptic_window_slice_{window_slice_counter}"

  if debug == 1:
    print(">>>> window_slice_counter= ", window_slice_counter)
  else:
    pass
    
  community_matrices_for_specific_window_slice = []

  for epileptic_participant in range(0, 100):

    if debug == 1:
      print(">>>>> epileptic_participant_number= ", epileptic_participant)
    
    else:
      pass

    epileptic_participant_data            = window_slice[:, :, epileptic_participant]
    epileptic_participant_data_transposed = epileptic_participant_data.T
    
    community_matrix_window_slice = window_kmeans_functional_similarity( \
                                  RUNS, k, epileptic_participant_data_transposed)
    community_matrices_for_specific_window_slice \
        .append(community_matrix_window_slice)

  # Save all the community matrices for each participant for the specific window
  # as a .npy file.
  dfc_save_cm(community_matrices_for_specific_window_slice, k, identifier)

  # Clear the list so that the next window's community matrices can be stored
  # there.
  community_matrices_for_specific_window_slice.clear()

debug = 1

RUNS       = 500
k          =  25

# Used with the identifer to save the community matrices .npy file for a 
# specific window. 1 = first 50 time slices, 2 = next 50 etc.
window_slice_counter = 0

for window_slice in epileptic_window_slices:

  # The identifier for the file name is updated to the correct window slice. 
  window_slice_counter = window_slice_counter + 1
  identifier           = f"epileptic_window_slice_{window_slice_counter}"

  if debug == 1:
    print(">>>> window_slice_counter= ", window_slice_counter)
  else:
    pass
    
  community_matrices_for_specific_window_slice = []

  for epileptic_participant in range(0, 100):

    if debug == 1:
      print(">>>>> epileptic_participant_number= ", epileptic_participant)
    
    else:
      pass

    epileptic_participant_data            = window_slice[:, :, epileptic_participant]
    epileptic_participant_data_transposed = epileptic_participant_data.T
    
    community_matrix_window_slice = window_kmeans_functional_similarity( \
                                  RUNS, k, epileptic_participant_data_transposed)
    community_matrices_for_specific_window_slice \
        .append(community_matrix_window_slice)

  # Save all the community matrices for each participant for the specific window
  # as a .npy file.
  dfc_save_cm(community_matrices_for_specific_window_slice, k, identifier)

  # Clear the list so that the next window's community matrices can be stored
  # there.
  community_matrices_for_specific_window_slice.clear()

debug = 1

RUNS       = 500
k          =  30

# Used with the identifer to save the community matrices .npy file for a 
# specific window. 1 = first 50 time slices, 2 = next 50 etc.
window_slice_counter = 0

for window_slice in epileptic_window_slices:

  # The identifier for the file name is updated to the correct window slice. 
  window_slice_counter = window_slice_counter + 1
  identifier           = f"epileptic_window_slice_{window_slice_counter}"

  if debug == 1:
    print(">>>> window_slice_counter= ", window_slice_counter)
  else:
    pass
    
  community_matrices_for_specific_window_slice = []

  for epileptic_participant in range(0, 100):

    if debug == 1:
      print(">>>>> epileptic_participant_number= ", epileptic_participant)
    
    else:
      pass

    epileptic_participant_data            = window_slice[:, :, epileptic_participant]
    epileptic_participant_data_transposed = epileptic_participant_data.T
    
    community_matrix_window_slice = window_kmeans_functional_similarity( \
                                  RUNS, k, epileptic_participant_data_transposed)
    community_matrices_for_specific_window_slice \
        .append(community_matrix_window_slice)

  # Save all the community matrices for each participant for the specific window
  # as a .npy file.
  dfc_save_cm(community_matrices_for_specific_window_slice, k, identifier)

  # Clear the list so that the next window's community matrices can be stored
  # there.
  community_matrices_for_specific_window_slice.clear()

debug = 1

RUNS       = 500
k          =  35

# Used with the identifer to save the community matrices .npy file for a 
# specific window. 1 = first 50 time slices, 2 = next 50 etc.
window_slice_counter = 0

for window_slice in epileptic_window_slices:

  # The identifier for the file name is updated to the correct window slice. 
  window_slice_counter = window_slice_counter + 1
  identifier           = f"epileptic_window_slice_{window_slice_counter}"

  if debug == 1:
    print(">>>> window_slice_counter= ", window_slice_counter)
  else:
    pass
    
  community_matrices_for_specific_window_slice = []

  for epileptic_participant in range(0, 100):

    if debug == 1:
      print(">>>>> epileptic_participant_number= ", epileptic_participant)
    
    else:
      pass

    epileptic_participant_data            = window_slice[:, :, epileptic_participant]
    epileptic_participant_data_transposed = epileptic_participant_data.T
    
    community_matrix_window_slice = window_kmeans_functional_similarity( \
                                  RUNS, k, epileptic_participant_data_transposed)
    community_matrices_for_specific_window_slice \
        .append(community_matrix_window_slice)

  # Save all the community matrices for each participant for the specific window
  # as a .npy file.
  dfc_save_cm(community_matrices_for_specific_window_slice, k, identifier)

  # Clear the list so that the next window's community matrices can be stored
  # there.
  community_matrices_for_specific_window_slice.clear()

debug = 1

RUNS       = 500
k          =  40

# Used with the identifer to save the community matrices .npy file for a 
# specific window. 1 = first 50 time slices, 2 = next 50 etc.
window_slice_counter = 0

for window_slice in epileptic_window_slices:

  # The identifier for the file name is updated to the correct window slice. 
  window_slice_counter = window_slice_counter + 1
  identifier           = f"epileptic_window_slice_{window_slice_counter}"

  if debug == 1:
    print(">>>> window_slice_counter= ", window_slice_counter)
  else:
    pass
    
  community_matrices_for_specific_window_slice = []

  for epileptic_participant in range(0, 100):

    if debug == 1:
      print(">>>>> epileptic_participant_number= ", epileptic_participant)
    
    else:
      pass

    epileptic_participant_data            = window_slice[:, :, epileptic_participant]
    epileptic_participant_data_transposed = epileptic_participant_data.T
    
    community_matrix_window_slice = window_kmeans_functional_similarity( \
                                  RUNS, k, epileptic_participant_data_transposed)
    community_matrices_for_specific_window_slice \
        .append(community_matrix_window_slice)

  # Save all the community matrices for each participant for the specific window
  # as a .npy file.
  dfc_save_cm(community_matrices_for_specific_window_slice, k, identifier)

  # Clear the list so that the next window's community matrices can be stored
  # there.
  community_matrices_for_specific_window_slice.clear()

debug = 1

RUNS       = 500
k          =  45

# Used with the identifer to save the community matrices .npy file for a 
# specific window. 1 = first 50 time slices, 2 = next 50 etc.
window_slice_counter = 0

for window_slice in epileptic_window_slices:

  # The identifier for the file name is updated to the correct window slice. 
  window_slice_counter = window_slice_counter + 1
  identifier           = f"epileptic_window_slice_{window_slice_counter}"

  if debug == 1:
    print(">>>> window_slice_counter= ", window_slice_counter)
  else:
    pass
    
  community_matrices_for_specific_window_slice = []

  for epileptic_participant in range(0, 100):

    if debug == 1:
      print(">>>>> epileptic_participant_number= ", epileptic_participant)
    
    else:
      pass

    epileptic_participant_data            = window_slice[:, :, epileptic_participant]
    epileptic_participant_data_transposed = epileptic_participant_data.T
    
    community_matrix_window_slice = window_kmeans_functional_similarity( \
                                  RUNS, k, epileptic_participant_data_transposed)
    community_matrices_for_specific_window_slice \
        .append(community_matrix_window_slice)

  # Save all the community matrices for each participant for the specific window
  # as a .npy file.
  dfc_save_cm(community_matrices_for_specific_window_slice, k, identifier)

  # Clear the list so that the next window's community matrices can be stored
  # there.
  community_matrices_for_specific_window_slice.clear()

debug = 1

RUNS       = 500
k          =  50

# Used with the identifer to save the community matrices .npy file for a 
# specific window. 1 = first 50 time slices, 2 = next 50 etc.
window_slice_counter = 0

for window_slice in epileptic_window_slices:

  # The identifier for the file name is updated to the correct window slice. 
  window_slice_counter = window_slice_counter + 1
  identifier           = f"epileptic_window_slice_{window_slice_counter}"

  if debug == 1:
    print(">>>> window_slice_counter= ", window_slice_counter)
  else:
    pass
    
  community_matrices_for_specific_window_slice = []

  for epileptic_participant in range(0, 100):

    if debug == 1:
      print(">>>>> epileptic_participant_number= ", epileptic_participant)
    
    else:
      pass

    epileptic_participant_data            = window_slice[:, :, epileptic_participant]
    epileptic_participant_data_transposed = epileptic_participant_data.T
    
    community_matrix_window_slice = window_kmeans_functional_similarity( \
                                  RUNS, k, epileptic_participant_data_transposed)
    community_matrices_for_specific_window_slice \
        .append(community_matrix_window_slice)

  # Save all the community matrices for each participant for the specific window
  # as a .npy file.
  dfc_save_cm(community_matrices_for_specific_window_slice, k, identifier)

  # Clear the list so that the next window's community matrices can be stored
  # there.
  community_matrices_for_specific_window_slice.clear()

"""# **Loading and visualising the dfc data**


---
"""

# Data is unzipped from the Drive into runtime local storage. 
!unzip "/content/drive/My Drive/window_slices.zip"

def visualise_four_window_slices(ws1, ws2, ws3, ws4, identifier, k_value, clmap):
  """
  """
  
  # Graphical plot.
  # Citations: https://matplotlib.org/3.1.0/gallery/subplots_axes_and_figures/subplots_demo.html;
  #            https://matplotlib.org/3.1.0/gallery/color/colorbar_basics.html
  #            https://stackoverflow.com/questions/10540929/figure-of-imshow-is-too-small (for figsize)
  fig, axis = plt.subplots(2, 2, figsize=(50, 50))
  pos1 = axis[0, 0].imshow(ws1, cmap=clmap, interpolation='none')
  axis[0, 0].set_title(f"{identifier}_{k_value}_ws1")

  pos2 = axis[0, 1].imshow(ws2, cmap=clmap, interpolation='none')
  axis[0, 1].set_title(f"{identifier}_{k_value}_ws2")

  pos3 = axis[1, 0].imshow(ws3, cmap=clmap, interpolation='none')
  axis[1, 0].set_title(f"{identifier}_{k_value}_ws3")

  pos4 = axis[1, 1].imshow(ws4, cmap=clmap, interpolation='none')
  axis[1, 1].set_title(f"{identifier}_{k_value}_ws4")

  fig.colorbar(pos1, ax=axis[0, 0])
  fig.colorbar(pos2, ax=axis[0, 1])
  fig.colorbar(pos3, ax=axis[1, 0])
  fig.colorbar(pos4, ax=axis[1, 1])

  plt.show()
  plt.close(fig)

healthy_k10_ws1 = np.load("/content/window_slices/healthy_window_slices/k10/healthy_window_slice_1_k10_cm.npy")
healthy_k10_ws2 = np.load("/content/window_slices/healthy_window_slices/k10/healthy_window_slice_2_k10_cm.npy")
healthy_k10_ws3 = np.load("/content/window_slices/healthy_window_slices/k10/healthy_window_slice_3_k10_cm.npy")
healthy_k10_ws4 = np.load("/content/window_slices/healthy_window_slices/k10/healthy_window_slice_4_k10_cm.npy")

mean_healthy_k10_ws1 = mean_community_matrix(healthy_k10_ws1)
mean_healthy_k10_ws2 = mean_community_matrix(healthy_k10_ws2)
mean_healthy_k10_ws3 = mean_community_matrix(healthy_k10_ws3)
mean_healthy_k10_ws4 = mean_community_matrix(healthy_k10_ws4)

visualise_four_window_slices(mean_healthy_k10_ws1, mean_healthy_k10_ws2, \
                             mean_healthy_k10_ws3, mean_healthy_k10_ws4, \
                             "healthy", 10, "PiYG")

epileptic_k10_ws1 = np.load("/content/window_slices/epileptic_window_slices/k10/epileptic_window_slice_1_k10_cm.npy")
epileptic_k10_ws2 = np.load("/content/window_slices/epileptic_window_slices/k10/epileptic_window_slice_2_k10_cm.npy")
epileptic_k10_ws3 = np.load("/content/window_slices/epileptic_window_slices/k10/epileptic_window_slice_3_k10_cm.npy")
epileptic_k10_ws4 = np.load("/content/window_slices/epileptic_window_slices/k10/epileptic_window_slice_4_k10_cm.npy")

mean_epileptic_k10_ws1 = mean_community_matrix(epileptic_k10_ws1)
mean_epileptic_k10_ws2 = mean_community_matrix(epileptic_k10_ws2)
mean_epileptic_k10_ws3 = mean_community_matrix(epileptic_k10_ws3)
mean_epileptic_k10_ws4 = mean_community_matrix(epileptic_k10_ws4)

visualise_four_window_slices(mean_epileptic_k10_ws1, mean_epileptic_k10_ws2, \
                             mean_epileptic_k10_ws3, mean_epileptic_k10_ws4, \
                             "epileptic", 10, "PiYG")

# Quantifiable visualisation. 

sum_ws1 = np.sum(mean_healthy_k10_ws1)
sum_ws2 = np.sum(mean_healthy_k10_ws2)
sum_ws3 = np.sum(mean_healthy_k10_ws3)
sum_ws4 = np.sum(mean_healthy_k10_ws4)
print(sum_ws1)
print(sum_ws2)
print(sum_ws3)
print(sum_ws4)

print(mean_healthy_k10_ws1)

"""# **dFC Classification: SVM**



---
"""

healthy_k10_ws1   = np.load("/content/window_slices/healthy_window_slices/k10/healthy_window_slice_1_k10_cm.npy")
epileptic_k10_ws1 = np.load("/content/window_slices/epileptic_window_slices/k10/epileptic_window_slice_1_k10_cm.npy")

# k = 10; ws1 experiment
k          =  10
ITERATIONS = 100
CLASSIFIER = "svm"

k_10_h_300_ws1_classification_accuracy_result = classification_process(healthy_k10_ws1, epileptic_k10_ws1, ITERATIONS, 300, CLASSIFIER, k)
k_10_h_350_ws1_classification_accuracy_result = classification_process(healthy_k10_ws1, epileptic_k10_ws1, ITERATIONS, 350, CLASSIFIER, k)
k_10_h_400_ws1_classification_accuracy_result = classification_process(healthy_k10_ws1, epileptic_k10_ws1, ITERATIONS, 400, CLASSIFIER, k)
k_10_h_450_ws1_classification_accuracy_result = classification_process(healthy_k10_ws1, epileptic_k10_ws1, ITERATIONS, 450, CLASSIFIER, k)
k_10_h_500_ws1_classification_accuracy_result = classification_process(healthy_k10_ws1, epileptic_k10_ws1, ITERATIONS, 500, CLASSIFIER, k)
k_10_h_550_ws1_classification_accuracy_result = classification_process(healthy_k10_ws1, epileptic_k10_ws1, ITERATIONS, 550, CLASSIFIER, k)
k_10_h_600_ws1_classification_accuracy_result = classification_process(healthy_k10_ws1, epileptic_k10_ws1, ITERATIONS, 600, CLASSIFIER, k)


print("K value, h value, window_slice, Average classification result, sensitivity, specificity, precision, f1_score:")

# Printed as a .csv format
for h in range(300, 650, 50):
  print(f"10, {h}, ws1", end=', ')
  # Citation: https://www.programiz.com/python-programming/methods/built-in/exec
  program = f"[print(item, end= ', ') for item in k_10_h_{h}_ws1_classification_accuracy_result]"
  exec(program)
  print("\n")

healthy_k10_ws2 = np.load("/content/window_slices/healthy_window_slices/k10/healthy_window_slice_2_k10_cm.npy")
healthy_k10_ws3 = np.load("/content/window_slices/healthy_window_slices/k10/healthy_window_slice_3_k10_cm.npy")
healthy_k10_ws4 = np.load("/content/window_slices/healthy_window_slices/k10/healthy_window_slice_4_k10_cm.npy")

epileptic_k10_ws2 = np.load("/content/window_slices/epileptic_window_slices/k10/epileptic_window_slice_2_k10_cm.npy")
epileptic_k10_ws3 = np.load("/content/window_slices/epileptic_window_slices/k10/epileptic_window_slice_3_k10_cm.npy")
epileptic_k10_ws4 = np.load("/content/window_slices/epileptic_window_slices/k10/epileptic_window_slice_4_k10_cm.npy")

# k = 10; ws2 experiment
k          =  10
ITERATIONS = 100
CLASSIFIER = "svm"

k_10_h_300_ws2_classification_accuracy_result = classification_process(healthy_k10_ws2, epileptic_k10_ws2, ITERATIONS, 300, CLASSIFIER, k)
k_10_h_350_ws2_classification_accuracy_result = classification_process(healthy_k10_ws2, epileptic_k10_ws2, ITERATIONS, 350, CLASSIFIER, k)
k_10_h_400_ws2_classification_accuracy_result = classification_process(healthy_k10_ws2, epileptic_k10_ws2, ITERATIONS, 400, CLASSIFIER, k)
k_10_h_450_ws2_classification_accuracy_result = classification_process(healthy_k10_ws2, epileptic_k10_ws2, ITERATIONS, 450, CLASSIFIER, k)
k_10_h_500_ws2_classification_accuracy_result = classification_process(healthy_k10_ws2, epileptic_k10_ws2, ITERATIONS, 500, CLASSIFIER, k)
k_10_h_550_ws2_classification_accuracy_result = classification_process(healthy_k10_ws2, epileptic_k10_ws2, ITERATIONS, 550, CLASSIFIER, k)
k_10_h_600_ws2_classification_accuracy_result = classification_process(healthy_k10_ws2, epileptic_k10_ws2, ITERATIONS, 600, CLASSIFIER, k)


print("K value, h value, window_slice, Average classification result, sensitivity, specificity, precision, f1_score:")

# Printed as a .csv format
for h in range(300, 650, 50):
  print(f"10, {h}, ws2", end=', ')
  # Citation: https://www.programiz.com/python-programming/methods/built-in/exec
  program = f"[print(item, end= ', ') for item in k_10_h_{h}_ws2_classification_accuracy_result]"
  exec(program)
  print("\n")
